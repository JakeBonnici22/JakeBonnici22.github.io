---
layout: default
modal-id: 5
date: 2023-01-30.
img: nlp.png
alt: image-alt
project-date: January, 2023.
client: Research Publication.
category: SemEval - Natural Language Processing
description: "
<h2>Learning Word-Sense and Image Embeddings for Word Sense Disambiguation.</h2>
Markchom, T., Liang, H., Gitau, J., Liu, Z., Ojha, V., Taylor, L., Bonnici, J., and Alshadadi, A. (2023) UoR-NCL at SemEval-2023 Task 1: Learning Word-Sense and Image Embeddings for Word Sense Disambiguation. In: SemEval-2023.


<p style='text-align: justify;'>
In SemEval-2023 Task 1, a task of applying
Word Sense Disambiguation in an image retrieval
system was introduced. To resolve this
task, this work proposes three approaches: (1)
an unsupervised approach considering similarities
between word senses and image captions,
(2) a supervised approach using a Siamese neural
network, and (3) a self-supervised approach
using a Bayesian personalized ranking framework.
According to the results, both supervised
and self-supervised approaches outperformed
the unsupervised approach. They can effectively
identify correct images of ambiguous
words in the dataset provided in this task.
</p>


<p style='text-align: justify;'>
In several natural languages, there are ambiguous
words that denote different meanings depending
on their contexts. For example, the word “bank”
in English may have different senses including “financial
institution” and “riverside”. To identify the
exact sense of an ambiguous word for a particular
context, a Natural Language Processing (NLP) task
called Word Sense Disambiguation (WSD) was introduced
(Navigli, 2009; Bevilacqua et al., 2021).
Despite the fact that WSD has been a long-standing
task, it is still challenging to apply WSD methods
to downstream NLP applications (Lopez de Lacalle
and Agirre, 2015; Raganato et al., 2017). Therefore,
the organizers of SemEval-2023 Task 1 proposed a
task of using WSD in an information retrieval system.
Specifically, given a word and some limited
textual context, the task is to select among a set
of candidate images the one corresponding to the
given word’s intended meaning.
According to the goal, two challenges are raised.
The first challenge is how to disambiguate a given
word based on a given context. Normally, a human
brain differentiates multiple senses of an ambiguous
word based on prior knowledge and experience.
Similarly, in the case of machines, external knowledge
is required to map an ambiguous word to
its actual meaning. Many knowledge-based WSD
methods have been relying on external lexical resources
such as WordNet (Miller, 1995). These
resources contain word senses which can be extracted
for disambiguation (Huang et al., 2019).
The second challenge is how to match a word with
an image. In many image retrieval systems, word
representations/embeddings and image representations/
embeddings are learned in a way that allows
word-image association (Bengio et al., 2013).
This work adopts this approach to learn word-sense
and image embeddings in order to associate word
senses with their corresponding images. We propose
three approaches utilizing WordNet to disambiguate
words and learn word-sense embeddings
and image embeddings for image retrieval. These
approaches are (1) an unsupervised approach using
word senses and image captions, (2) a supervised
approach using a Siamese neural network to learn
word-sense and image embeddings, and (3) a selfsupervised
contrastive learning approach using a
Bayesian personalized ranking framework.
</p>


<p style='text-align: justify;'>
An NLP-based approach for determining the similarity
between sentences is implemented. This
approach starts with loading a dataset including
word senses and image captions generated as aforementioned.
Each word sense/image caption is preprocessed
by using spaCy’s NLP functions3. This
includes removing stop words, lemmatizing the
words, and creating a new text string from the lemmatized
words. Then, for each word, the cosine
similarity between its concatenated word senses
and a caption of each candidate image is computed.
The image with the highest similarity is finally selected
as an answer.
</p>



"
---
